{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60026fdb",
   "metadata": {},
   "source": [
    "# Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f76d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import queue\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time\n",
    "from knn_model_builder import build_knn_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da24d7",
   "metadata": {},
   "source": [
    "# Define the node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17f61439",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, state,h, parent=None, action=None, g=0, f=0, crop_type=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.g = g  # Cumulative cost from start to this node\n",
    "        self.f = f  # Evaluation cost (g + heuristic if applicable)\n",
    "        self.h = h\n",
    "        self.crop_type = crop_type  # Store the crop type associated with this state\n",
    "        # Calculate the depth of the node\n",
    "        if parent is None:\n",
    "            self.depth = 0\n",
    "        else:\n",
    "            self.depth = parent.depth + 1\n",
    "\n",
    "    def __hash__(self):  # Return hash value for each Node to access it from hash tables (e.g., sets)\n",
    "        if isinstance(self.state, list):\n",
    "            state_tuple = tuple([tuple(row) for row in self.state])\n",
    "            return hash(state_tuple)\n",
    "        return hash(self.state)\n",
    "\n",
    "    def __eq__(self, other):  # Helps to check duplicates in the sets\n",
    "        return isinstance(other, Node) and self.state == other.state\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return isinstance(other, Node) and self.f > other.f\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return isinstance(other, Node) and self.f < other.f\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"State: {self.state}, Crop: {self.crop_type}, f-value: {self.f}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba60e9",
   "metadata": {},
   "source": [
    "# A* porblem formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a64d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CropsPredictionProblem:\n",
    "    def __init__(self, state_space, goal_state, crop_labels, actions=\"\", path_cost=0):\n",
    "        self.state_space = np.array(state_space)  # Matrix each row represents an environement for the entire crooptypes\n",
    "        self.goal_state = goal_state\n",
    "        self.actions = actions\n",
    "        self.path_cost = path_cost\n",
    "        # the following are some necessary attritbute that are derived from the previouse one\n",
    "        self.crop_labels = crop_labels  # Crop type corresponding to each row\n",
    "        self.distance_calculations = 0 \n",
    "        self.weights = [\n",
    "            0.100,  # N\n",
    "            0.127,  # P\n",
    "            0.153,  # K\n",
    "            0.080,  # temperature\n",
    "            0.188,  # humidity\n",
    "            0.059,  # ph\n",
    "            0.195,  # rainfall\n",
    "            0.008,  # soil_moisture\n",
    "            0.002,  # soil_type\n",
    "            0.009,  # sunlight_exposure\n",
    "            0.009,  # wind_speed\n",
    "            0.009,  # co2_concentration\n",
    "            0.008,  # organic_matter\n",
    "            0.004,  # irrigation_frequency\n",
    "            0.007,  # crop_density\n",
    "            0.008,  # pest_pressure\n",
    "            0.008,  # fertilizer_usage\n",
    "            0.002,  # growth_stage\n",
    "            0.007,  # urban_area_proximity\n",
    "            0.002,  # water_source_type\n",
    "            0.008,  # frost_risk\n",
    "            0.008   # water_usage_efficiency\n",
    "        ]\n",
    "        \n",
    "        # Group environments by crop type\n",
    "        self.crop_environments = defaultdict(list)\n",
    "        self.crop_indices = defaultdict(list)  # Keep track of original indices\n",
    "        for i, crop_type in enumerate(crop_labels):\n",
    "            self.crop_environments[crop_type].append(tuple(state_space[i]))\n",
    "            self.crop_indices[crop_type].append(i)\n",
    "        self.knn_models, self.crop_initial_envs = build_knn_models(self.crop_environments, self.weights)# the knn model represent the state transition model and inital env represent the initial state \n",
    "        self.crop_labels = list(set(crop_labels))\n",
    "    \n",
    "    def get_hcost(self, state):\n",
    "        \"\"\"Calculate heuristic cost (distance to goal state)\"\"\"\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = tuple(state)\n",
    "            \n",
    "        sum_distance = 0\n",
    "        for i in range(len(state)):\n",
    "            sum_distance += abs(state[i] - self.goal_state[i]) * self.weights[i]\n",
    "        \n",
    "        return sum_distance\n",
    "    \n",
    "    def get_gcost(self, parent_state, state, crop_label=None):\n",
    "        \"\"\"Calculate g cost (distance from initial state)\"\"\"\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = tuple(state)\n",
    "        if isinstance(parent_state, np.ndarray):\n",
    "            parent_state = tuple(parent_state)\n",
    "        sum_distance = 0\n",
    "        return sum(\n",
    "            abs(state[i] - parent_state[i]) * self.weights[i]\n",
    "            for i in range(len(state))\n",
    "        )\n",
    "    def expand_node(self, node):\n",
    "        \"\"\"\n",
    "        Optimized expand node function:\n",
    "        - First level: consider all crop types (using their best environment)\n",
    "        - Subsequent levels: stay within the current crop type\n",
    "        \"\"\"\n",
    "        child_nodes = []\n",
    "        current_state = node.state\n",
    "        current_crop_type = node.crop_type\n",
    "        knn_model = self.knn_models[current_crop_type]\n",
    "        environments = np.array(self.crop_environments[current_crop_type])\n",
    "        distances, indices = knn_model.kneighbors([current_state])\n",
    "        for idx in indices[0]:\n",
    "            neighbor_state = tuple(environments[idx])\n",
    "            if neighbor_state == current_state:\n",
    "                continue\n",
    "            g_cost = self.get_gcost(neighbor_state , node.state , current_crop_type)\n",
    "            h_cost = self.get_hcost(neighbor_state)\n",
    "            f_cost = g_cost + h_cost\n",
    "            child_node = Node(\n",
    "                state=neighbor_state,\n",
    "                parent=node,\n",
    "                g=g_cost,\n",
    "                f=f_cost,\n",
    "                h=h_cost,\n",
    "                crop_type=current_crop_type,\n",
    "               action=f\"move_within_{current_crop_type}\"\n",
    "            )\n",
    "            child_nodes.append(child_node)\n",
    "        return child_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c5198",
   "metadata": {},
   "source": [
    "# The A* algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5a0c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AStarSearch:\n",
    "    def __init__(self, problem):\n",
    "        self.problem = problem\n",
    "        self.frontier = queue.PriorityQueue()\n",
    "        self.explored = set()\n",
    "        self.best_nodes_by_crop = dict()  #Track best node found for each crop type\n",
    "\n",
    "        # Add these metrics tracking variables\n",
    "        self.nodes_expanded = 0\n",
    "        self.max_frontier_size = 0\n",
    "        self.execution_time = 0\n",
    "\n",
    "    def search(self):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for croptype in self.problem.crop_labels:# we search for each crop type \n",
    "            self.frontier = queue.PriorityQueue()\n",
    "            self.explored = set()\n",
    "            initial_state = self.problem.crop_initial_envs[croptype]\n",
    "            f_cost = self.problem.get_hcost(initial_state)\n",
    "            initial_node = Node(initial_state , g=0 , f=f_cost , crop_type=croptype , h=f_cost )\n",
    "            self.frontier.put((initial_node.f, initial_node))\n",
    "            while not self.frontier.empty() : \n",
    "                _ , node = self.frontier.get()\n",
    "                self.explored.add(node)\n",
    "                self.nodes_expanded += 1\n",
    "                child_nodes = self.problem.expand_node(node)\n",
    "                for child in child_nodes : \n",
    "                    if child in self.explored : \n",
    "                        continue \n",
    "                    self.frontier.put((child.f , child))\n",
    "                # and then check whether the current state has h less than the top of the frontier and than return it\n",
    "                if not self.frontier.empty():\n",
    "                    top_f, top_node = self.frontier.queue[0]\n",
    "                    if node.h < top_node.h:\n",
    "                        self.best_nodes_by_crop[croptype] = node.state\n",
    "                    else:\n",
    "                        self.best_nodes_by_crop[croptype] = node.state\n",
    "                self.max_frontier_size = max(self.max_frontier_size, self.frontier.qsize())\n",
    "            self.execution_time = time.time() - start_time\n",
    "        return self.best_nodes_by_crop \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130ab4e",
   "metadata": {},
   "source": [
    "# Test the A* algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c033035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_best_crop(user_input, state_space, crop_labels):\n",
    "    \"\"\"\n",
    "    Use A* search to find the best crop type based on environment similarity.\n",
    "    Focuses only on finding the closest environment to the user input.\n",
    "    \"\"\"\n",
    "    # Create the problem instance\n",
    "    problem = CropsPredictionProblem(\n",
    "        state_space=state_space,\n",
    "        goal_state=user_input,\n",
    "        crop_labels=crop_labels\n",
    "    )\n",
    "\n",
    "    # Initialize and run A* search\n",
    "    a_star = AStarSearch(problem)\n",
    "    best_nodes = a_star.search()  # Maps crop types to best environment (state tuple)\n",
    "\n",
    "    # Sort crop types by their h-cost (distance to user input)\n",
    "    sorted_crops = sorted(\n",
    "        [(crop, {'environment': best_nodes[crop], 'score': problem.get_hcost(best_nodes[crop])}) \n",
    "         for crop in best_nodes],\n",
    "        key=lambda x: x[1]['score']\n",
    "    )\n",
    "\n",
    "    # Recommended crop is the one with lowest h-cost\n",
    "    recommended_crop = sorted_crops[0][0] if sorted_crops else None\n",
    "\n",
    "    # Format crop scores for output\n",
    "    crop_scores = {\n",
    "        crop: {\n",
    "            'environment': best_nodes[crop],\n",
    "            'score': problem.get_hcost(best_nodes[crop])\n",
    "        } for crop in best_nodes\n",
    "    }\n",
    "\n",
    "    # Format ranked crops\n",
    "    ranked_crops = []\n",
    "    for i, (crop, data) in enumerate(sorted_crops):\n",
    "        ranked_crops.append({\n",
    "            'rank': i + 1,\n",
    "            'cropType': crop,\n",
    "            'score': round(data['score'], 2),\n",
    "            'environment': [round(val, 2) for val in data['environment']]\n",
    "        })\n",
    "\n",
    "    total_computational_units = a_star.nodes_expanded + problem.distance_calculations\n",
    "\n",
    "    return {\n",
    "        'recommended_crop': recommended_crop,\n",
    "        'metrics': {\n",
    "            'nodesExpanded': a_star.nodes_expanded,\n",
    "            'maxFrontierSize': a_star.max_frontier_size,\n",
    "            'executionTime': round(a_star.execution_time, 3),\n",
    "        },\n",
    "        'rankings': ranked_crops\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96638e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended crop: chickpea\n",
      "\n",
      "Ranked crop types (lower score is better):\n",
      "Rank : 1 -> chickpea with the score : 27.93\n",
      "Rank : 2 -> lentil with the score : 28.79\n",
      "Rank : 3 -> mothbeans with the score : 29.92\n",
      "Rank : 4 -> muskmelon with the score : 32.06\n",
      "Rank : 5 -> mango with the score : 32.39\n",
      "Rank : 6 -> watermelon with the score : 35.86\n",
      "Rank : 7 -> kidneybeans with the score : 36.56\n",
      "Rank : 8 -> blackgram with the score : 36.63\n",
      "Rank : 9 -> mungbean with the score : 38.1\n",
      "Rank : 10 -> pomegranate with the score : 40.87\n",
      "Rank : 11 -> maize with the score : 43.72\n",
      "Rank : 12 -> cotton with the score : 44.9\n",
      "Rank : 13 -> orange with the score : 49.03\n",
      "Rank : 14 -> papaya with the score : 49.88\n",
      "Rank : 15 -> banana with the score : 51.47\n",
      "Rank : 16 -> pigeonpeas with the score : 52.48\n",
      "Rank : 17 -> coffee with the score : 57.15\n",
      "Rank : 18 -> jute with the score : 63.0\n",
      "Rank : 19 -> coconut with the score : 63.62\n",
      "Rank : 20 -> grapes with the score : 67.34\n",
      "Rank : 21 -> rice with the score : 70.32\n",
      "Rank : 22 -> apple with the score : 77.13\n",
      "{'recommended_crop': 'chickpea', 'metrics': {'nodesExpanded': 475, 'maxFrontierSize': 6, 'executionTime': 0.314}, 'rankings': [{'rank': 1, 'cropType': 'chickpea', 'score': np.float64(27.93), 'environment': [np.float64(48.0), np.float64(65.0), np.float64(78.0), np.float64(17.44), np.float64(14.34), np.float64(7.86), np.float64(73.09), np.float64(26.67), np.float64(2.0), np.float64(7.53), np.float64(14.44), np.float64(416.76), np.float64(3.83), np.float64(6.0), np.float64(13.83), np.float64(55.82), np.float64(95.01), np.float64(3.0), np.float64(39.65), np.float64(1.0), np.float64(57.72), np.float64(3.98)]}, {'rank': 2, 'cropType': 'lentil', 'score': np.float64(28.79), 'environment': [np.float64(1.0), np.float64(67.0), np.float64(21.0), np.float64(27.52), np.float64(60.54), np.float64(6.55), np.float64(48.06), np.float64(20.11), np.float64(1.0), np.float64(11.79), np.float64(16.06), np.float64(371.88), np.float64(5.69), np.float64(4.0), np.float64(16.78), np.float64(16.59), np.float64(174.76), np.float64(3.0), np.float64(34.82), np.float64(2.0), np.float64(82.44), np.float64(3.9)]}, {'rank': 3, 'cropType': 'mothbeans', 'score': np.float64(29.92), 'environment': [np.float64(24.0), np.float64(37.0), np.float64(21.0), np.float64(30.57), np.float64(58.23), np.float64(5.82), np.float64(62.75), np.float64(25.3), np.float64(2.0), np.float64(6.46), np.float64(9.12), np.float64(388.27), np.float64(2.0), np.float64(6.0), np.float64(5.2), np.float64(8.86), np.float64(193.5), np.float64(1.0), np.float64(8.25), np.float64(2.0), np.float64(58.61), np.float64(4.59)]}, {'rank': 4, 'cropType': 'muskmelon', 'score': np.float64(32.06), 'environment': [np.float64(110.0), np.float64(22.0), np.float64(47.0), np.float64(29.03), np.float64(91.82), np.float64(6.24), np.float64(24.94), np.float64(11.52), np.float64(2.0), np.float64(10.92), np.float64(15.6), np.float64(353.53), np.float64(2.87), np.float64(1.0), np.float64(7.78), np.float64(11.92), np.float64(136.88), np.float64(3.0), np.float64(37.84), np.float64(3.0), np.float64(57.83), np.float64(4.16)]}, {'rank': 5, 'cropType': 'mango', 'score': np.float64(32.39), 'environment': [np.float64(23.0), np.float64(23.0), np.float64(27.0), np.float64(34.72), np.float64(51.43), np.float64(5.16), np.float64(97.31), np.float64(10.11), np.float64(2.0), np.float64(7.85), np.float64(5.45), np.float64(400.04), np.float64(10.0), np.float64(2.0), np.float64(9.12), np.float64(34.52), np.float64(122.34), np.float64(2.0), np.float64(4.54), np.float64(1.0), np.float64(21.24), np.float64(4.83)]}, {'rank': 6, 'cropType': 'watermelon', 'score': np.float64(35.86), 'environment': [np.float64(109.0), np.float64(21.0), np.float64(55.0), np.float64(24.9), np.float64(89.74), np.float64(6.77), np.float64(57.45), np.float64(24.42), np.float64(3.0), np.float64(5.7), np.float64(3.76), np.float64(427.01), np.float64(9.71), np.float64(5.0), np.float64(17.15), np.float64(17.05), np.float64(108.49), np.float64(2.0), np.float64(34.16), np.float64(3.0), np.float64(9.07), np.float64(2.06)]}, {'rank': 7, 'cropType': 'kidneybeans', 'score': np.float64(36.56), 'environment': [np.float64(32.0), np.float64(57.0), np.float64(18.0), np.float64(15.54), np.float64(23.76), np.float64(5.7), np.float64(107.39), np.float64(26.76), np.float64(3.0), np.float64(9.45), np.float64(11.95), np.float64(442.94), np.float64(7.56), np.float64(3.0), np.float64(10.72), np.float64(38.83), np.float64(176.81), np.float64(3.0), np.float64(47.79), np.float64(2.0), np.float64(75.29), np.float64(1.05)]}, {'rank': 8, 'cropType': 'blackgram', 'score': np.float64(36.63), 'environment': [np.float64(44.0), np.float64(55.0), np.float64(25.0), np.float64(29.63), np.float64(65.91), np.float64(7.42), np.float64(71.16), np.float64(14.59), np.float64(1.0), np.float64(9.12), np.float64(19.08), np.float64(388.6), np.float64(5.98), np.float64(5.0), np.float64(18.62), np.float64(9.06), np.float64(156.84), np.float64(3.0), np.float64(45.37), np.float64(3.0), np.float64(29.3), np.float64(1.93)]}, {'rank': 9, 'cropType': 'mungbean', 'score': np.float64(38.1), 'environment': [np.float64(33.0), np.float64(57.0), np.float64(17.0), np.float64(27.9), np.float64(88.72), np.float64(6.78), np.float64(57.8), np.float64(24.23), np.float64(3.0), np.float64(9.03), np.float64(5.09), np.float64(406.38), np.float64(8.43), np.float64(6.0), np.float64(8.58), np.float64(47.01), np.float64(90.37), np.float64(3.0), np.float64(3.64), np.float64(3.0), np.float64(14.18), np.float64(4.76)]}, {'rank': 10, 'cropType': 'pomegranate', 'score': np.float64(40.87), 'environment': [np.float64(29.0), np.float64(22.0), np.float64(40.0), np.float64(23.63), np.float64(89.73), np.float64(6.15), np.float64(107.68), np.float64(26.84), np.float64(2.0), np.float64(9.53), np.float64(14.74), np.float64(438.22), np.float64(2.89), np.float64(2.0), np.float64(11.04), np.float64(53.78), np.float64(168.47), np.float64(2.0), np.float64(2.92), np.float64(3.0), np.float64(10.72), np.float64(3.95)]}, {'rank': 11, 'cropType': 'maize', 'score': np.float64(43.72), 'environment': [np.float64(71.0), np.float64(54.0), np.float64(16.0), np.float64(22.61), np.float64(63.69), np.float64(5.75), np.float64(87.76), np.float64(28.16), np.float64(1.0), np.float64(10.46), np.float64(14.64), np.float64(418.13), np.float64(8.56), np.float64(1.0), np.float64(17.4), np.float64(91.21), np.float64(162.71), np.float64(2.0), np.float64(15.25), np.float64(2.0), np.float64(61.72), np.float64(3.8)]}, {'rank': 12, 'cropType': 'cotton', 'score': np.float64(44.9), 'environment': [np.float64(108.0), np.float64(46.0), np.float64(17.0), np.float64(24.3), np.float64(84.88), np.float64(6.93), np.float64(65.02), np.float64(10.89), np.float64(2.0), np.float64(10.08), np.float64(3.94), np.float64(399.77), np.float64(3.71), np.float64(3.0), np.float64(14.42), np.float64(4.95), np.float64(73.31), np.float64(3.0), np.float64(36.26), np.float64(1.0), np.float64(54.6), np.float64(1.72)]}, {'rank': 13, 'cropType': 'orange', 'score': np.float64(49.03), 'environment': [np.float64(24.0), np.float64(27.0), np.float64(9.0), np.float64(18.87), np.float64(93.25), np.float64(6.16), np.float64(119.39), np.float64(11.21), np.float64(2.0), np.float64(7.7), np.float64(1.31), np.float64(368.01), np.float64(1.23), np.float64(3.0), np.float64(6.7), np.float64(30.19), np.float64(185.38), np.float64(3.0), np.float64(46.94), np.float64(2.0), np.float64(33.87), np.float64(1.52)]}, {'rank': 14, 'cropType': 'papaya', 'score': np.float64(49.88), 'environment': [np.float64(59.0), np.float64(62.0), np.float64(49.0), np.float64(43.36), np.float64(93.35), np.float64(6.94), np.float64(114.78), np.float64(28.77), np.float64(1.0), np.float64(8.88), np.float64(1.01), np.float64(359.25), np.float64(8.03), np.float64(1.0), np.float64(18.82), np.float64(89.61), np.float64(81.93), np.float64(1.0), np.float64(27.13), np.float64(3.0), np.float64(37.01), np.float64(1.17)]}, {'rank': 15, 'cropType': 'banana', 'score': np.float64(51.47), 'environment': [np.float64(85.0), np.float64(89.0), np.float64(51.0), np.float64(29.21), np.float64(84.7), np.float64(6.16), np.float64(108.55), np.float64(14.48), np.float64(1.0), np.float64(9.01), np.float64(13.48), np.float64(427.5), np.float64(9.9), np.float64(5.0), np.float64(9.22), np.float64(93.27), np.float64(92.48), np.float64(2.0), np.float64(16.92), np.float64(2.0), np.float64(9.7), np.float64(3.25)]}, {'rank': 16, 'cropType': 'pigeonpeas', 'score': np.float64(52.48), 'environment': [np.float64(18.0), np.float64(58.0), np.float64(16.0), np.float64(21.48), np.float64(38.8), np.float64(4.96), np.float64(180.38), np.float64(22.34), np.float64(3.0), np.float64(5.17), np.float64(17.59), np.float64(357.04), np.float64(7.81), np.float64(3.0), np.float64(9.52), np.float64(21.38), np.float64(53.68), np.float64(2.0), np.float64(14.97), np.float64(1.0), np.float64(11.29), np.float64(3.09)]}, {'rank': 17, 'cropType': 'coffee', 'score': np.float64(57.15), 'environment': [np.float64(88.0), np.float64(21.0), np.float64(27.0), np.float64(24.43), np.float64(66.02), np.float64(7.23), np.float64(181.64), np.float64(26.45), np.float64(1.0), np.float64(8.07), np.float64(11.58), np.float64(419.99), np.float64(8.13), np.float64(2.0), np.float64(7.47), np.float64(54.99), np.float64(66.89), np.float64(3.0), np.float64(19.26), np.float64(2.0), np.float64(67.35), np.float64(3.22)]}, {'rank': 18, 'cropType': 'jute', 'score': np.float64(63.0), 'environment': [np.float64(69.0), np.float64(57.0), np.float64(35.0), np.float64(24.31), np.float64(78.54), np.float64(6.19), np.float64(186.23), np.float64(15.92), np.float64(1.0), np.float64(11.24), np.float64(12.38), np.float64(367.33), np.float64(6.49), np.float64(3.0), np.float64(15.97), np.float64(5.4), np.float64(189.26), np.float64(3.0), np.float64(42.06), np.float64(3.0), np.float64(88.13), np.float64(1.14)]}, {'rank': 19, 'cropType': 'coconut', 'score': np.float64(63.62), 'environment': [np.float64(34.0), np.float64(15.0), np.float64(34.0), np.float64(27.06), np.float64(91.11), np.float64(5.68), np.float64(224.7), np.float64(24.18), np.float64(1.0), np.float64(11.83), np.float64(0.48), np.float64(410.23), np.float64(8.78), np.float64(1.0), np.float64(13.43), np.float64(36.26), np.float64(196.93), np.float64(2.0), np.float64(21.76), np.float64(1.0), np.float64(60.49), np.float64(1.66)]}, {'rank': 20, 'cropType': 'grapes', 'score': np.float64(67.34), 'environment': [np.float64(37.0), np.float64(144.0), np.float64(197.0), np.float64(11.19), np.float64(80.81), np.float64(6.42), np.float64(66.34), np.float64(16.09), np.float64(1.0), np.float64(6.16), np.float64(7.65), np.float64(414.05), np.float64(3.48), np.float64(4.0), np.float64(6.78), np.float64(71.09), np.float64(165.64), np.float64(3.0), np.float64(10.4), np.float64(3.0), np.float64(41.87), np.float64(1.1)]}, {'rank': 21, 'cropType': 'rice', 'score': np.float64(70.32), 'environment': [np.float64(74.0), np.float64(35.0), np.float64(40.0), np.float64(26.49), np.float64(80.16), np.float64(6.98), np.float64(242.86), np.float64(26.21), np.float64(3.0), np.float64(8.02), np.float64(7.96), np.float64(363.69), np.float64(8.39), np.float64(1.0), np.float64(10.86), np.float64(24.09), np.float64(55.76), np.float64(3.0), np.float64(10.86), np.float64(3.0), np.float64(82.82), np.float64(1.27)]}, {'rank': 22, 'cropType': 'apple', 'score': np.float64(77.13), 'environment': [np.float64(14.0), np.float64(139.0), np.float64(197.0), np.float64(21.72), np.float64(92.84), np.float64(6.06), np.float64(121.7), np.float64(15.74), np.float64(1.0), np.float64(11.35), np.float64(4.0), np.float64(402.97), np.float64(1.66), np.float64(1.0), np.float64(11.59), np.float64(99.6), np.float64(171.33), np.float64(2.0), np.float64(35.17), np.float64(2.0), np.float64(24.48), np.float64(2.64)]}]}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    file_path = 'data.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract features and labels\n",
    "    X = df.drop(df.columns[7], axis=1).to_numpy()  # Drop the crop column\n",
    "    y = df.iloc[:, 7].tolist()  # Crop labels\n",
    "    \n",
    "    user_input = 0,5,55,29.68846716,9,6.168757984,26.83924845,16.062880963574187,3,10.516192328761576,7.923933040671249,416.77274994527374,7.3726710345678415,4,6.326215721268702,33.17820170878281,77.87450358965383,3,26.917565055237162,2,83.0439742163446,2.1862823701170457\n",
    "    \n",
    "\n",
    "    results = predict_best_crop(user_input, X, y)\n",
    "    \n",
    "    print(f\"Recommended crop: {results['recommended_crop']}\")\n",
    "    print(\"\\nRanked crop types (lower score is better):\")\n",
    "    for x in results[\"rankings\"]:\n",
    "        print(f\"Rank : {x['rank']} -> {x['cropType']} with the score : {x['score']}\")\n",
    "    print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
